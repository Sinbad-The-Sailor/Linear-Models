{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Statistical Classification\n",
    "We want to classify women working and predict wheter or not a new sample is working. This inference is based the set of features shown below. \n",
    "\n",
    "* $x_1$: Husband's income\n",
    "* $x_2$: Years of education\n",
    "* $x_3$: Years of work experience\n",
    "* $x_4$: Age\n",
    "* $x_5$: Number of children < 6 years\n",
    "* $x_6$: Number of children > 6 years\n",
    "\n",
    "The dataset will be split (70/30) into training and testing data. Two classification models will be used: logistic regression (parametric model) and k-nearest-neighbors (non-parametric model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Plotting configuration\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.style.use(['science', 'notebook', 'grid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Work</th>\n",
       "      <th>Constant</th>\n",
       "      <th>HusbandInc</th>\n",
       "      <th>EducYears</th>\n",
       "      <th>ExpYears</th>\n",
       "      <th>Age</th>\n",
       "      <th>NSmallChild</th>\n",
       "      <th>NBigChild</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.394940</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.232000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.271990</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.069000</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.799889</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Work          Constant      HusbandInc    EducYears      ExpYears      Age  \\\n",
       "0   1.0               1.0       22.394940         12.0           7.0     43.0   \n",
       "1   0.0               1.0        7.232000          8.0          10.0     34.0   \n",
       "2   1.0               1.0       18.271990         12.0           4.0     41.0   \n",
       "3   0.0               1.0       28.069000         14.0           2.0     43.0   \n",
       "4   1.0               1.0        7.799889         12.0          10.0     31.0   \n",
       "\n",
       "             NSmallChild    NBigChild  \n",
       "0                    0.0          3.0  \n",
       "1                    0.0          7.0  \n",
       "2                    1.0          5.0  \n",
       "3                    0.0          2.0  \n",
       "4                    0.0          1.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/WomenAtWork.dat', delimiter='\\t', engine='python')\n",
    "\n",
    "split_index = int(np.ceil(0.7 * len(df)))\n",
    "df_training = df[0:split_index]\n",
    "df_test = df[split_index:]\n",
    "df_training.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "\n",
    "We begin by applying logistic regression. Logistic regression is a transformed version of linear regression, which limits the output to $[0,1]$, which represents a probability of being in a class or not. Note, we are only making inference on one class.\n",
    "\n",
    "For logistic regression, we transform the $y_i$ using the Sigmoid function defined as: $f(x) \\triangleq \\frac{1}{1 + e^x}$. Thus we obtain the following model for our classification problem:\n",
    "$$\n",
    "\\mathbb{P}({y_i}=1| \\mathbf{x}, \\mathbf{\\theta}) = \\frac{1}{1 + \\exp \\{\\theta_0 + \\theta_1 x_1 + \\ldots + \\theta_6 x_6\\}} = \\frac{1}{1 + \\exp \\{\\mathbf{x}^{\\text{T}}\\mathbf{\\theta}\\}}\n",
    "$$\n",
    "\n",
    "The sample of observations $\\{y_i\\}_{i=1}^n$ can now be intepreted as a sequence of Bernoulli random variables. Thus we can obtain the following log-likelihood function rather easily:\n",
    "\n",
    "$$\n",
    "-\\ell(\\bold{X}, \\bold{y} | \\mathbf{\\theta}) = \\sum_{i=1}^n \\big[(y_i-1)\\mathbf{\\theta}^{\\text{T}}\\mathbf{x}_i - \\ln(1+\\exp\\{\\mathbf{\\theta}^{\\text{T}}\\mathbf{x}_i\\})\\big]\n",
    "$$\n",
    "\n",
    "Next, we fit the model to the training data using the log-likelihood function above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create log-likelihood function\n",
    "def log_likelihood(params: np.array, y: np.array, X: np.array) -> float:\n",
    "    assert(len(y) == len(X))\n",
    "    n_observations = len(y)\n",
    "\n",
    "    log_likelihood = 0\n",
    "    for i in range(0, n_observations):\n",
    "        log_likelihood = (log_likelihood \n",
    "                          + (y[i] - 1) * params.T @ X[i] \n",
    "                          - np.log(1 + np.exp(params.T @ X[i]))\n",
    "                          )\n",
    "\n",
    "    return -log_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      fun: -5868.388311078871\n",
      " hess_inv: array([[ 9.99832205e-01, -5.88539765e-03, -4.12636800e-02,\n",
      "        -1.20090647e-02, -7.72931440e-04,  2.23093126e-02,\n",
      "        -1.46074370e-02],\n",
      "       [-5.88539765e-03,  3.12365277e-02, -1.78575774e-02,\n",
      "         4.31540619e-02, -3.11629478e-02, -5.69531144e-02,\n",
      "         3.29055267e-02],\n",
      "       [-4.12636800e-02, -1.78575774e-02,  4.37715170e-01,\n",
      "         1.05496357e-01, -1.62324274e-01, -1.59406947e-01,\n",
      "        -3.12551115e-02],\n",
      "       [-1.20090647e-02,  4.31540619e-02,  1.05496357e-01,\n",
      "         2.47152703e-01, -1.67960960e-01, -2.51264373e-01,\n",
      "         1.65930894e-01],\n",
      "       [-7.72931440e-04, -3.11629478e-02, -1.62324274e-01,\n",
      "        -1.67960960e-01,  1.42627796e-01,  1.98858569e-01,\n",
      "        -1.03236398e-01],\n",
      "       [ 2.23093126e-02, -5.69531144e-02, -1.59406947e-01,\n",
      "        -2.51264373e-01,  1.98858569e-01,  1.33976224e+00,\n",
      "        -1.43210003e-01],\n",
      "       [-1.46074370e-02,  3.29055267e-02, -3.12551115e-02,\n",
      "         1.65930894e-01, -1.03236398e-01, -1.43210003e-01,\n",
      "         1.04070093e+00]])\n",
      "      jac: array([  70.24005127, 1427.75341797,  877.1708374 ,  760.27874756,\n",
      "       2831.00561523,   24.99945068,   82.0838623 ])\n",
      "  message: 'Desired error not necessarily achieved due to precision loss.'\n",
      "     nfev: 174\n",
      "      nit: 4\n",
      "     njev: 21\n",
      "   status: 2\n",
      "  success: False\n",
      "        x: array([ -0.18957731,   2.92383871,  10.34427792,  13.94884381,\n",
      "       -10.52807357,  -6.26910652,   3.07821976])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d7/rpl_88f12ln2z1s2h4m9ybjm0000gn/T/ipykernel_54986/152974731.py:10: RuntimeWarning: overflow encountered in exp\n",
      "  - np.log(1 + np.exp(params.T @ X[i]))\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/scipy/optimize/_numdiff.py:557: RuntimeWarning: invalid value encountered in subtract\n",
      "  df = fun(x) - f0\n",
      "/var/folders/d7/rpl_88f12ln2z1s2h4m9ybjm0000gn/T/ipykernel_54986/152974731.py:10: RuntimeWarning: overflow encountered in exp\n",
      "  - np.log(1 + np.exp(params.T @ X[i]))\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "# Format training data in numpy.\n",
    "y = np.array(df_training[df_training.columns[0]])\n",
    "X = np.array(df_training[df_training.columns[1:]])\n",
    "params = 0 * np.ones(7)\n",
    "\n",
    "# Find MLE parameters.\n",
    "sol = minimize(log_likelihood, x0=params, args=(y, X))\n",
    "sol.x\n",
    "print(sol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier(data: np.array, params: np.array, threshold: float = 0.5) -> int:\n",
    "    prob = 1 / (1 + np.exp(params.T @ data))\n",
    "    if prob > threshold:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def classify_data(data: np.array, params: np.array) -> np.array:\n",
    "    n_observations = len(data)\n",
    "    prediction = np.zeros(n_observations)\n",
    "\n",
    "    for i in range(0, n_observations):\n",
    "        prediction[i] = classifier(data[i], params)\n",
    "\n",
    "    return prediction\n",
    "\n",
    "mle_params = sol.x\n",
    "data = np.array(df_test[df_test.columns[1:]])\n",
    "validation = np.array(df_test[df_test.columns[0]])\n",
    "prediction = classify_data(data, mle_params)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
       "       1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1.,\n",
       "       1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24\n"
     ]
    }
   ],
   "source": [
    "successes = abs(validation-prediction)\n",
    "successes = np.sum([1 for i in successes if i==0])\n",
    "accuracy = successes / len(validation)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy & Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kNN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy & Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
