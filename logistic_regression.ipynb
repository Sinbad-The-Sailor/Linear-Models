{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Statistical Classification\n",
    "We want to classify women working and predict wheter or not a new sample is working. This inference is based the set of features shown below. \n",
    "\n",
    "* $x_1$: Husband's income\n",
    "* $x_2$: Years of education\n",
    "* $x_3$: Years of work experience\n",
    "* $x_4$: Age\n",
    "* $x_5$: Number of children < 6 years\n",
    "* $x_6$: Number of children > 6 years\n",
    "\n",
    "The dataset will be split (70/30) into training and testing data. Two classification models will be used: logistic regression (parametric model) and k-nearest-neighbors (non-parametric model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Plotting configuration\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.style.use(['science', 'notebook', 'grid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/WomenAtWork.dat', delimiter='\\t', engine='python')\n",
    "\n",
    "split_index = int(np.ceil(0.7 * len(df)))\n",
    "df_training = df[0:split_index]\n",
    "df_test = df[split_index:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "\n",
    "We begin by applying logistic regression. Logistic regression is a transformed version of linear regression, which limits the output to $[0,1]$, which represents a probability of being in a class or not. Note, we are only making inference on one class.\n",
    "\n",
    "For logistic regression, we transform the $y_i$ using the Sigmoid function defined as: $f(x) \\triangleq \\frac{1}{1 + e^x}$. Thus we obtain the following model for our classification problem:\n",
    "$$\n",
    "\\mathbb{P}({y_i}=1| \\mathbf{x}, \\mathbf{\\theta}) = \\frac{1}{1 + \\exp \\{\\theta_0 + \\theta_1 x_1 + \\ldots + \\theta_6 x_6\\}} = \\frac{1}{1 + \\exp \\{\\mathbf{x}^{\\text{T}}\\mathbf{\\theta}\\}}\n",
    "$$\n",
    "\n",
    "The sample of observations $\\{y_i\\}_{i=1}^n$ can now be intepreted as a sequence of Bernoulli random variables. Thus we can obtain the following log-likelihood function rather easily:\n",
    "\n",
    "$$\n",
    "-\\ell(\\bold{X}, \\bold{y} | \\mathbf{\\theta}) = \\sum_{i=1}^n \\big[(y_i-1)\\mathbf{\\theta}^{\\text{T}}\\mathbf{x}_i - \\ln(1+\\exp\\{\\mathbf{\\theta}^{\\text{T}}\\mathbf{x}_i\\})\\big]\n",
    "$$\n",
    "\n",
    "Next, we fit the model to the training data using the log-likelihood function above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy & Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kNN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy & Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
